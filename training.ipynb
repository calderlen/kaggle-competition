{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import polars as pl\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_constructor(df):\n",
    "    \"\"\"\n",
    "    Group words in a DataFrame based on the 'activity' column.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The input DataFrame containing the 'activity' column.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: The modified DataFrame with additional columns 'word_start' and 'word_end' indicating the boundaries of words.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize columns for word beginnings and endings\n",
    "    df['word_start'] = 0\n",
    "    df['word_end'] = 0\n",
    "    \n",
    "    # Shifting the activity columns up and down one for subsequent calculations\n",
    "    shifted_activity_prev = df['activity'].shift(1)\n",
    "    shifted_activity_next = df['activity'].shift(-1)\n",
    "    \n",
    "    # Identification of word boundaries\n",
    "    df['word_start'] = ((df['activity'] == 'Input') & (shifted_activity_prev != 'Input')).astype(int)\n",
    "    df['word_end'] = ((df['activity'] == 'Input') & (shifted_activity_next != 'Input')).astype(int)\n",
    "    \n",
    "    # Handling edge cases: adressing first and last column of datafraem\n",
    "    df.at[0, 'word_start'] = int(df.iloc[0]['activity'] == 'Input')\n",
    "    df.at[df.index[-1], 'word_end'] = int(df.iloc[-1]['activity'] == 'Input')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_constructor(df):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(df):\n",
    "    \n",
    "    df = word_constructor(df)\n",
    "    df = sentence_constructor(df)\n",
    "    \n",
    "    # Calculate IKI for all events\n",
    "    df['iki'] = df['down_time'].diff().fillna(0)\n",
    "\n",
    "    # Initialize columns for intra-word IKI and inter-word IKI with NaN\n",
    "    df['intra_word_iki'] = np.nan\n",
    "    df['inter_word_iki'] = np.nan\n",
    "\n",
    "    # Identify the start and end of words\n",
    "    word_starts = df['word_start'] == 1\n",
    "    word_ends = df['word_end'] == 1\n",
    "\n",
    "    # Compute intra-word and inter-word IKI\n",
    "    df.loc[word_starts, 'inter_word_iki'] = df.loc[word_starts, 'iki']\n",
    "    df.loc[~word_starts & ~word_ends, 'intra_word_iki'] = df.loc[~word_starts & ~word_ends, 'iki']\n",
    "    \n",
    "    # IKI FEATURES\n",
    "    # Create a DataFrame to store the features with a single column of IDs\n",
    "    features = pd.DataFrame({'id': df['id'].unique()})\n",
    "    \n",
    "    # Computing median, standard deviation, and maximum IKI, intra-word IKI, and inter-word IKI\n",
    "\n",
    "    agg_functions = ['median', 'std', 'max']\n",
    "    iki_basics = df.groupby('id')['iki'].agg(agg_functions).reset_index()\n",
    "    intra_word_iki_basics = df.groupby('id')['intra_word_iki'].agg(agg_functions).reset_index()\n",
    "    inter_word_iki_basics = df.groupby('id')['inter_word_iki'].agg(agg_functions).reset_index()\n",
    "\n",
    "    # Renaming the columns\n",
    "    iki_basics.columns = ['id'] + [f'iki_{f}' for f in agg_functions]\n",
    "    intra_word_iki_basics.columns = ['id'] + [f'intra_word_iki_{f}' for f in agg_functions]\n",
    "    inter_word_iki_basics.columns = ['id'] + [f'inter_word_iki_{f}' for f in agg_functions]\n",
    "\n",
    "    # Computing number of IKIs within length intervals\n",
    "    \n",
    "    # Define the length intervals\n",
    "    intervals = [0.5, 1, 1.5, 2, 2.5, 3, np.inf]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Merging IKI features\n",
    "    features = features.merge(iki_basics, on='id')\n",
    "    features = features.merge(intra_word_iki_basics, on='id')\n",
    "    features = features.merge(inter_word_iki_basics, on='id')\n",
    "\n",
    "\n",
    "    # REVISION FEATURES\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "df_train = pd.read_csv('data/train_logs.csv', \n",
    "                 header=0)\n",
    "df_test = pd.read_csv('data/test_logs.csv', \n",
    "                 header=0)\n",
    "df_train_scores = pd.read_csv('data/train_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = features(df_train)\n",
    "features_test = features(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging training features with training scores\n",
    "df_train_merged = features_train.merge(df_train_scores, on='id')\n",
    "\n",
    "# Splitting the merged data into features and target variable\n",
    "X_train = df_train_merged.drop(['id', 'score'], axis=1)  # Dropping 'id' as it's not a feature\n",
    "y_train = df_train_merged['score']\n",
    "\n",
    "# Map scores to integers\n",
    "score_mapping = {0.5: 0, 1: 1, 1.5: 2, 2: 3, 2.5: 4, 3: 5, 3.5: 6, 4: 7, 4.5: 8, 5: 9, 5.5: 10, 6: 11}\n",
    "reverse_mapping = {v: k for k, v in score_mapping.items()}\n",
    "y_train_mapped = y_train.map(score_mapping)\n",
    "\n",
    "\n",
    "X_test = features_test.drop('id', axis=1)  # Dropping 'id' as it's not a feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "df_train_merged.head()\n",
    "print(type(y_train[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.000 GB of training data: 0.015 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 trees, 336 leaves (28 on avg), max depth = 12, in 0.089s\n",
      "[2/100] 12 trees, 372 leaves (31 on avg), max depth = 15, in 0.055s\n",
      "[3/100] 12 trees, 372 leaves (31 on avg), max depth = 16, in 0.133s\n",
      "[4/100] 12 trees, 372 leaves (31 on avg), max depth = 14, in 0.053s\n",
      "[5/100] 12 trees, 372 leaves (31 on avg), max depth = 15, in 0.047s\n",
      "[6/100] 12 trees, 372 leaves (31 on avg), max depth = 16, in 0.044s\n",
      "[7/100] 12 trees, 372 leaves (31 on avg), max depth = 13, in 0.048s\n",
      "[8/100] 12 trees, 372 leaves (31 on avg), max depth = 19, in 0.052s\n",
      "[9/100] 12 trees, 372 leaves (31 on avg), max depth = 19, in 0.052s\n",
      "[10/100] 12 trees, 372 leaves (31 on avg), max depth = 20, in 0.079s\n",
      "[11/100] 12 trees, 372 leaves (31 on avg), max depth = 17, in 0.050s\n",
      "[12/100] 12 trees, 372 leaves (31 on avg), max depth = 20, in 0.049s\n",
      "[13/100] 12 trees, 372 leaves (31 on avg), max depth = 22, in 0.053s\n",
      "[14/100] 12 trees, 372 leaves (31 on avg), max depth = 20, in 0.048s\n",
      "[15/100] 12 trees, 372 leaves (31 on avg), max depth = 19, in 0.043s\n",
      "[16/100] 12 trees, 372 leaves (31 on avg), max depth = 22, in 0.043s\n",
      "[17/100] 12 trees, 372 leaves (31 on avg), max depth = 20, in 0.053s\n",
      "[18/100] 12 trees, 372 leaves (31 on avg), max depth = 19, in 0.049s\n",
      "[19/100] 12 trees, 372 leaves (31 on avg), max depth = 20, in 0.043s\n",
      "[20/100] 12 trees, 372 leaves (31 on avg), max depth = 22, in 0.071s\n",
      "[21/100] 12 trees, 372 leaves (31 on avg), max depth = 19, in 0.068s\n",
      "[22/100] 12 trees, 372 leaves (31 on avg), max depth = 22, in 0.220s\n",
      "[23/100] 12 trees, 372 leaves (31 on avg), max depth = 22, in 0.097s\n",
      "[24/100] 12 trees, 372 leaves (31 on avg), max depth = 23, in 0.084s\n",
      "[25/100] 12 trees, 372 leaves (31 on avg), max depth = 21, in 0.113s\n",
      "[26/100] 12 trees, 372 leaves (31 on avg), max depth = 22, in 0.080s\n",
      "[27/100] 12 trees, 372 leaves (31 on avg), max depth = 23, in 0.083s\n",
      "[28/100] 12 trees, 372 leaves (31 on avg), max depth = 17, in 0.060s\n",
      "[29/100] 12 trees, 372 leaves (31 on avg), max depth = 22, in 0.057s\n",
      "[30/100] 12 trees, 372 leaves (31 on avg), max depth = 23, in 0.058s\n",
      "[31/100] 12 trees, 372 leaves (31 on avg), max depth = 21, in 0.067s\n",
      "[32/100] 12 trees, 372 leaves (31 on avg), max depth = 23, in 0.068s\n",
      "[33/100] 12 trees, 372 leaves (31 on avg), max depth = 23, in 0.113s\n",
      "[34/100] 12 trees, 372 leaves (31 on avg), max depth = 22, in 0.080s\n",
      "[35/100] 12 trees, 372 leaves (31 on avg), max depth = 20, in 0.058s\n",
      "[36/100] 12 trees, 372 leaves (31 on avg), max depth = 22, in 0.050s\n",
      "[37/100] 12 trees, 372 leaves (31 on avg), max depth = 21, in 0.050s\n",
      "[38/100] 12 trees, 372 leaves (31 on avg), max depth = 26, in 0.055s\n",
      "[39/100] 12 trees, 372 leaves (31 on avg), max depth = 19, in 0.082s\n",
      "[40/100] 12 trees, 372 leaves (31 on avg), max depth = 22, in 0.053s\n",
      "[41/100] 12 trees, 372 leaves (31 on avg), max depth = 22, in 0.057s\n",
      "[42/100] 12 trees, 372 leaves (31 on avg), max depth = 22, in 0.065s\n",
      "[43/100] 12 trees, 372 leaves (31 on avg), max depth = 23, in 0.066s\n",
      "[44/100] 12 trees, 372 leaves (31 on avg), max depth = 20, in 0.072s\n",
      "[45/100] 12 trees, 372 leaves (31 on avg), max depth = 23, in 0.106s\n",
      "[46/100] 12 trees, 372 leaves (31 on avg), max depth = 22, in 0.118s\n",
      "[47/100] 12 trees, 372 leaves (31 on avg), max depth = 19, in 0.098s\n",
      "[48/100] 12 trees, 372 leaves (31 on avg), max depth = 21, in 0.105s\n",
      "[49/100] 12 trees, 372 leaves (31 on avg), max depth = 19, in 0.108s\n",
      "[50/100] 12 trees, 372 leaves (31 on avg), max depth = 21, in 0.105s\n",
      "[51/100] 12 trees, 372 leaves (31 on avg), max depth = 20, in 0.050s\n",
      "[52/100] 12 trees, 372 leaves (31 on avg), max depth = 21, in 0.053s\n",
      "[53/100] 12 trees, 372 leaves (31 on avg), max depth = 19, in 0.057s\n",
      "[54/100] 12 trees, 372 leaves (31 on avg), max depth = 18, in 0.056s\n",
      "[55/100] 12 trees, 370 leaves (30 on avg), max depth = 18, in 0.058s\n",
      "[56/100] 12 trees, 372 leaves (31 on avg), max depth = 20, in 0.051s\n",
      "[57/100] 12 trees, 372 leaves (31 on avg), max depth = 19, in 0.047s\n",
      "[58/100] 12 trees, 368 leaves (30 on avg), max depth = 23, in 0.062s\n",
      "[59/100] 12 trees, 367 leaves (30 on avg), max depth = 21, in 0.058s\n",
      "[60/100] 12 trees, 364 leaves (30 on avg), max depth = 21, in 0.050s\n",
      "[61/100] 12 trees, 362 leaves (30 on avg), max depth = 21, in 0.070s\n",
      "[62/100] 12 trees, 363 leaves (30 on avg), max depth = 24, in 0.048s\n",
      "[63/100] 12 trees, 361 leaves (30 on avg), max depth = 19, in 0.056s\n",
      "[64/100] 12 trees, 363 leaves (30 on avg), max depth = 19, in 0.056s\n",
      "[65/100] 12 trees, 358 leaves (29 on avg), max depth = 18, in 0.050s\n",
      "[66/100] 12 trees, 361 leaves (30 on avg), max depth = 23, in 0.061s\n",
      "[67/100] 12 trees, 362 leaves (30 on avg), max depth = 23, in 0.049s\n",
      "[68/100] 12 trees, 361 leaves (30 on avg), max depth = 23, in 0.054s\n",
      "[69/100] 12 trees, 359 leaves (29 on avg), max depth = 19, in 0.073s\n",
      "[70/100] 12 trees, 358 leaves (29 on avg), max depth = 19, in 0.086s\n",
      "[71/100] 12 trees, 357 leaves (29 on avg), max depth = 24, in 0.081s\n",
      "[72/100] 12 trees, 356 leaves (29 on avg), max depth = 20, in 0.077s\n",
      "[73/100] 12 trees, 354 leaves (29 on avg), max depth = 19, in 0.089s\n",
      "[74/100] 12 trees, 353 leaves (29 on avg), max depth = 18, in 0.051s\n",
      "[75/100] 12 trees, 354 leaves (29 on avg), max depth = 19, in 0.048s\n",
      "[76/100] 12 trees, 353 leaves (29 on avg), max depth = 18, in 0.051s\n",
      "[77/100] 12 trees, 352 leaves (29 on avg), max depth = 19, in 0.043s\n",
      "[78/100] 12 trees, 351 leaves (29 on avg), max depth = 18, in 0.149s\n",
      "[79/100] 12 trees, 351 leaves (29 on avg), max depth = 22, in 0.072s\n",
      "[80/100] 12 trees, 351 leaves (29 on avg), max depth = 20, in 0.062s\n",
      "[81/100] 12 trees, 350 leaves (29 on avg), max depth = 22, in 0.053s\n",
      "[82/100] 12 trees, 349 leaves (29 on avg), max depth = 19, in 0.064s\n",
      "[83/100] 12 trees, 350 leaves (29 on avg), max depth = 18, in 0.064s\n",
      "[84/100] 12 trees, 349 leaves (29 on avg), max depth = 20, in 0.048s\n",
      "[85/100] 12 trees, 351 leaves (29 on avg), max depth = 22, in 0.049s\n",
      "[86/100] 12 trees, 350 leaves (29 on avg), max depth = 22, in 0.044s\n",
      "[87/100] 12 trees, 349 leaves (29 on avg), max depth = 21, in 0.061s\n",
      "[88/100] 12 trees, 348 leaves (29 on avg), max depth = 20, in 0.051s\n",
      "[89/100] 12 trees, 348 leaves (29 on avg), max depth = 19, in 0.049s\n",
      "[90/100] 12 trees, 347 leaves (28 on avg), max depth = 22, in 0.058s\n",
      "[91/100] 12 trees, 347 leaves (28 on avg), max depth = 18, in 0.046s\n",
      "[92/100] 12 trees, 347 leaves (28 on avg), max depth = 22, in 0.044s\n",
      "[93/100] 12 trees, 347 leaves (28 on avg), max depth = 21, in 0.048s\n",
      "[94/100] 12 trees, 346 leaves (28 on avg), max depth = 20, in 0.053s\n",
      "[95/100] 12 trees, 347 leaves (28 on avg), max depth = 23, in 0.049s\n",
      "[96/100] 12 trees, 347 leaves (28 on avg), max depth = 19, in 0.053s\n",
      "[97/100] 12 trees, 346 leaves (28 on avg), max depth = 19, in 0.052s\n",
      "[98/100] 12 trees, 345 leaves (28 on avg), max depth = 16, in 0.058s\n",
      "[99/100] 12 trees, 346 leaves (28 on avg), max depth = 18, in 0.106s\n",
      "[100/100] 12 trees, 346 leaves (28 on avg), max depth = 19, in 0.049s\n",
      "Fit 1200 trees in 6.656 s, (36360 total leaves)\n",
      "Time spent computing histograms: 2.070s\n",
      "Time spent finding best splits:  1.165s\n",
      "Time spent applying splits:      1.931s\n",
      "Time spent predicting:           0.068s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HistGradientBoostingClassifier(random_state=42, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingClassifier(random_state=42, verbose=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "HistGradientBoostingClassifier(random_state=42, verbose=1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HistGradientBoostingClassifier(max_iter=100, max_leaf_nodes=31, early_stopping='auto', random_state=42, verbose=1, scoring='loss')\n",
    "model.fit(X_train, y_train_mapped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and reverse map\n",
    "y_pred_mapped = model.predict(X_test)\n",
    "y_pred = pd.Series(y_pred_mapped).map(reverse_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3.5\n",
      "1    3.0\n",
      "2    4.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
