{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Features__\n",
    "- **id**: Users (2471)\n",
    "- **event_id**: Individual event; sequential; starting from 1\n",
    "    - mean: 2070\n",
    "    - SD: 1590\n",
    "    - max: 12900\n",
    "- **down_time**\n",
    "- **up_time**\n",
    "- **action_time**\n",
    "- **activity**\n",
    "    - options\n",
    "        1. Nonproduction\n",
    "        2. Input\n",
    "        3. Remove/Cut\n",
    "        4. Replace\n",
    "        5. Paste\n",
    "        6. Move From [x1, y1] To [x2, y2]\n",
    "- **down_event**\n",
    "- **up_event**\n",
    "    - options\n",
    "        1. q\n",
    "        2. Leftclick\n",
    "        3. .\n",
    "        4. ,\n",
    "        5. Backspace\n",
    "        6. Space\n",
    "        7. \n",
    "- **text_change**\n",
    "    - options\n",
    "        1. NoChange\n",
    "        2. q\n",
    "        3. \n",
    "        4. Replace (ex: qqqqq qqq => qq)\n",
    "        5. \n",
    "- **cursor_position**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### __Derived Keystroke Features__ (From: [Early prediction of writing quality using keystroke logging](https://doi.org/10.1007/s40593-021-00268-w))\n",
    "\n",
    "- Features related to timing of pauses\n",
    "    - **Initial pause time**\n",
    "    - **Total time**\n",
    "    - **IKI**\n",
    "        - *Mean*\n",
    "        - *Median*\n",
    "        - *SD*\n",
    "        - *Max*\n",
    "    - **IKI within word**\n",
    "        - *Mean*\n",
    "        - *SD*\n",
    "    - **IKI between words**\n",
    "        - *Mean*\n",
    "        - *SD*\n",
    "    - **Time between words**\n",
    "        - *Mean*\n",
    "        - *SD*\n",
    "    - **Time between sentences**\n",
    "        - *Mean*\n",
    "        - *SD*\n",
    "    - **Number of IKI of specific length**\n",
    "    - **Percentage long pauses between words**\n",
    "- Features related to revisions\n",
    "    - **Number of revisions**\n",
    "    - **Number of leading-edge revisions**\n",
    "    - **Number of in-text revisions**\n",
    "    - **Number of backspaces**\n",
    "    - **Time in single backspacing**\n",
    "        - *Mean*\n",
    "        - *SD*\n",
    "    - **Percentage of characters in final text**\n",
    "    - **Percentage of characters at leading edge**\n",
    "- Features related to fluency\n",
    "    - **Number of characters per burst**\n",
    "        - *Mean*\n",
    "        - *SD*\n",
    "        - *Max*\n",
    "    - **Number of bursts**\n",
    "    - **Percentage of R-bursts:** number of revision bursts at leading edge ending in a revision\n",
    "    - **Percentage of I-bursts:** number of insertion bursts produced away from the leading edge\n",
    "    - **Percentage of words in P-bursts:** number of words in 'clean' production bursts both initiated and terminated by a long pause (not a revision)\n",
    "    - **Number of production cycles**\n",
    "    - **Percentage of linear transitions between words**\n",
    "    - **Percentage of linear transitions between sentences**\n",
    "- Features related to verbosity\n",
    "    - **Total number of keystrokes**\n",
    "    - **Total number of words**\n",
    "    - **SD number of keystrokes per 30s**\n",
    "    - **Slope of the number of keystrokes per 30s**\n",
    "    - **Entropy of the number of keystrokes per 30s**\n",
    "    - **Uniformity of the number of keystrokes per 30s**\n",
    "    - **Local extreme number of keystrokes per 30s**\n",
    "    - **Distance 30s windows of more than one keystroke**\n",
    "        - *Mean*\n",
    "        - *SD*\n",
    "- Features related to other events\n",
    "    - **Number of focus shifts to translation or task**\n",
    "    - **cut/paste/jump events**\n",
    "        - *Mean*\n",
    "        - *SD*\n",
    "    - **Percentage of time spent on other events**\n",
    "    \n",
    "Note: IKI == Interkeystroke interval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "\n",
    "# absolutely necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# temporarily necessary packages\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "df_train = pd.read_csv('data/train_logs.csv', \n",
    "                 header=0)\n",
    "df_test = pd.read_csv('data/test_logs.csv', \n",
    "                 header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  event_id  down_time  up_time  action_time       activity  \\\n",
      "0  001519c8         1       4526     4557           31  Nonproduction   \n",
      "1  001519c8         2       4558     4962          404  Nonproduction   \n",
      "2  001519c8         3     106571   106571            0  Nonproduction   \n",
      "3  001519c8         4     106686   106777           91          Input   \n",
      "4  001519c8         5     107196   107323          127          Input   \n",
      "\n",
      "  down_event   up_event text_change  cursor_position  word_count  \n",
      "0  Leftclick  Leftclick    NoChange                0           0  \n",
      "1  Leftclick  Leftclick    NoChange                0           0  \n",
      "2      Shift      Shift    NoChange                0           0  \n",
      "3          q          q           q                1           1  \n",
      "4          q          q           q                2           1  \n"
     ]
    }
   ],
   "source": [
    "print(df_train.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2471\n",
      "\n",
      " ['Nonproduction' 'Input' 'Remove/Cut' 'Replace'\n",
      " 'Move From [284, 292] To [282, 290]' 'Move From [287, 289] To [285, 287]'\n",
      " 'Move From [460, 461] To [465, 466]' 'Paste'\n",
      " 'Move From [905, 1314] To [907, 1316]'\n",
      " 'Move From [565, 743] To [669, 847]' 'Move From [669, 847] To [565, 743]'\n",
      " 'Move From [1041, 1121] To [1496, 1576]'\n",
      " 'Move From [1455, 1557] To [1323, 1425]'\n",
      " 'Move From [2268, 2275] To [2247, 2254]'\n",
      " 'Move From [213, 302] To [902, 991]' 'Move From [0, 158] To [234, 392]'\n",
      " 'Move From [460, 465] To [925, 930]' 'Move From [810, 906] To [816, 912]'\n",
      " 'Move From [186, 187] To [184, 185]' 'Move From [140, 272] To [299, 431]'\n",
      " 'Move From [114, 140] To [272, 298]'\n",
      " 'Move From [1386, 1450] To [1445, 1509]'\n",
      " 'Move From [442, 524] To [296, 378]' 'Move From [408, 414] To [390, 396]'\n",
      " 'Move From [1144, 1147] To [1142, 1145]'\n",
      " 'Move From [218, 220] To [206, 208]' 'Move From [164, 165] To [153, 154]'\n",
      " 'Move From [623, 632] To [624, 633]'\n",
      " 'Move From [747, 960] To [1041, 1254]'\n",
      " 'Move From [274, 314] To [299, 339]' 'Move From [624, 625] To [845, 846]'\n",
      " 'Move From [1861, 2063] To [1766, 1968]'\n",
      " 'Move From [1766, 1968] To [1861, 2063]'\n",
      " 'Move From [2091, 2179] To [252, 340]'\n",
      " 'Move From [923, 1077] To [340, 494]' 'Move From [0, 1] To [590, 591]'\n",
      " 'Move From [999, 1000] To [1000, 1001]' 'Move From [13, 65] To [9, 61]'\n",
      " 'Move From [1651, 1769] To [1565, 1683]' 'Move From [61, 136] To [0, 75]'\n",
      " 'Move From [0, 75] To [1, 76]' 'Move From [75, 134] To [304, 363]'\n",
      " 'Move From [289, 355] To [562, 628]'\n",
      " 'Move From [944, 1102] To [1050, 1208]'\n",
      " 'Move From [1306, 1371] To [1061, 1126]'\n",
      " 'Move From [1061, 1126] To [1306, 1371]'\n",
      " 'Move From [1361, 1362] To [1358, 1359]'\n",
      " 'Move From [51, 86] To [109, 144]' 'Move From [134, 169] To [122, 157]'\n",
      " 'Move From [382, 437] To [458, 513]']\n",
      "\n",
      " ['NoChange' 'q' ' ' ... 'qq qqq qqqq qqqqq' 'qq qqqqq qqqq qq qqqqq '\n",
      " '\\n qqqqq qqqqqq qqqqqqqqqq qq q qqqqqqqq qqq qqq qqqq qqqqqq q qqq. \\n\\nqqqq qqq qq qqqqqqq qqq:\\n- \\n- qqq qqqqqqq qqqq q qqqqqq qqqqqqqq qq qqqq qqqqqqqq ']\n",
      "\n",
      " ['Leftclick' 'Shift' 'q' 'Space' 'Backspace' '.' ',' 'Enter' 'ArrowLeft'\n",
      " \"'\" ';' 'ArrowRight' '-' '?' 'Tab' '\"' 'ArrowUp' 'ArrowDown' 'm'\n",
      " 'Rightclick' 'i' 'o' 't' '=' 'a' 'CapsLock' 'Control' 'c' 'v' '/'\n",
      " 'Delete' ':' 'z' '[' '$' '(' ')' '+' 'Home' 'End' '\\\\' 'Meta' '*' '&'\n",
      " 'AudioVolumeMute' 'x' '!' 'Insert' 'MediaPlayPause' 'w' 'NumLock' '%' 'V'\n",
      " 'b' '>' 'Alt' 'AudioVolumeUp' 'ContextMenu' 'AudioVolumeDown' 'n' 'e' '<'\n",
      " 'PageDown' ']' 'Middleclick' '@' 'F12' 'u' 'j' 's' '\\x96' 'Dead' 'y' '{'\n",
      " 'ScrollLock' '¿' 'p' 'Process' '}' 'MediaTrackPrevious' 'MediaTrackNext'\n",
      " 'F3' '^' 'Unidentified' 'Cancel' 'h' '2' 'd' 'r' '`' '\\x9b' 'f' 'g' '#'\n",
      " '~' 'PageUp' 'l' 'T' 'A' 'S' 'ModeChange' '_' 'Escape' 'F11'\n",
      " 'Unknownclick' 'AltGraph' 'F10' 'F15' 'Clear' 'OS' 'C' 'Ä±' 'M' '|'\n",
      " 'â\\x80\\x93' '0' '1' '5' '\\x97' 'Ë\\x86' '¡' '\\x80' 'Â´' 'Å\\x9f' 'F2' 'ä'\n",
      " 'F1' 'k' 'Pause' 'F6']\n"
     ]
    }
   ],
   "source": [
    "print(df_train['id'].nunique())\n",
    "print('\\n',df_train['activity'].unique())\n",
    "print('\\n',df_train['text_change'].unique())\n",
    "print('\\n',df_train['up_event'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     False\n",
      "1     False\n",
      "2     False\n",
      "3      True\n",
      "4      True\n",
      "5      True\n",
      "6      True\n",
      "7      True\n",
      "8      True\n",
      "9     False\n",
      "10     True\n",
      "11     True\n",
      "12     True\n",
      "13    False\n",
      "14     True\n",
      "15     True\n",
      "16     True\n",
      "17     True\n",
      "18     True\n",
      "19     True\n",
      "Name: text_change, dtype: bool\n",
      "(8405898,)\n"
     ]
    }
   ],
   "source": [
    "is_alnum = df_train['text_change'].str.contains('q')\n",
    "print(is_alnum.head(20))\n",
    "print(is_alnum.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_grouping(df):\n",
    "    is_alnum = df['text_change'].str.contains('q')\n",
    "    word_count = [0] * len(is_alnum)  # Initialize with zeros\n",
    "    j = 0\n",
    "\n",
    "    for i in range(len(is_alnum)):\n",
    "        word_count[i] = j\n",
    "        if not is_alnum.iloc[i] and is_alnum.iloc[i + 1]:\n",
    "            j += 1\n",
    "\n",
    "    word_count[-1] = j  # Last element\n",
    "    \n",
    "    return pd.Series(word_count)  # Return as a Pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iw_iki(df):\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text_change'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.12/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:160\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index_class_helper.pxi:70\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text_change'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/calder/Documents/kaggle-competition/main.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/calder/Documents/kaggle-competition/main.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m iw_iki(df_train)\n",
      "\u001b[1;32m/home/calder/Documents/kaggle-competition/main.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/calder/Documents/kaggle-competition/main.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39miw_iki\u001b[39m(df):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/calder/Documents/kaggle-competition/main.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     df\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m'\u001b[39;49m\u001b[39mtext_change\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(word_grouping)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/calder/Documents/kaggle-competition/main.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.12/site-packages/pandas/core/groupby/generic.py:228\u001b[0m, in \u001b[0;36mSeriesGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m@Appender\u001b[39m(\n\u001b[1;32m    223\u001b[0m     _apply_docs[\u001b[39m\"\u001b[39m\u001b[39mtemplate\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    224\u001b[0m         \u001b[39minput\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mseries\u001b[39m\u001b[39m\"\u001b[39m, examples\u001b[39m=\u001b[39m_apply_docs[\u001b[39m\"\u001b[39m\u001b[39mseries_examples\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    225\u001b[0m     )\n\u001b[1;32m    226\u001b[0m )\n\u001b[1;32m    227\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mself\u001b[39m, func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series:\n\u001b[0;32m--> 228\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mapply(func, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1766\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1765\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1766\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_apply_general(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selected_obj)\n\u001b[1;32m   1767\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   1768\u001b[0m         \u001b[39m# gh-20949\u001b[39;00m\n\u001b[1;32m   1769\u001b[0m         \u001b[39m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1773\u001b[0m         \u001b[39m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m         \u001b[39m# on a string grouper column\u001b[39;00m\n\u001b[1;32m   1776\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_python_apply_general(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj_with_exclusions)\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1815\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1780\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m   1781\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_python_apply_general\u001b[39m(\n\u001b[1;32m   1782\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1787\u001b[0m     is_agg: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1788\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NDFrameT:\n\u001b[1;32m   1789\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1790\u001b[0m \u001b[39m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1791\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1813\u001b[0m \u001b[39m        data after applying f\u001b[39;00m\n\u001b[1;32m   1814\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1815\u001b[0m     values, mutated \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrouper\u001b[39m.\u001b[39;49mapply_groupwise(f, data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxis)\n\u001b[1;32m   1816\u001b[0m     \u001b[39mif\u001b[39;00m not_indexed_same \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1817\u001b[0m         not_indexed_same \u001b[39m=\u001b[39m mutated\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.12/site-packages/pandas/core/groupby/ops.py:905\u001b[0m, in \u001b[0;36mBaseGrouper.apply_groupwise\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[39m# group might be modified\u001b[39;00m\n\u001b[1;32m    904\u001b[0m group_axes \u001b[39m=\u001b[39m group\u001b[39m.\u001b[39maxes\n\u001b[0;32m--> 905\u001b[0m res \u001b[39m=\u001b[39m f(group)\n\u001b[1;32m    906\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mutated \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    907\u001b[0m     mutated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;32m/home/calder/Documents/kaggle-competition/main.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/calder/Documents/kaggle-competition/main.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mword_grouping\u001b[39m(df):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/calder/Documents/kaggle-competition/main.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     word_count \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/calder/Documents/kaggle-competition/main.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     is_alnum \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mtext_change\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mcontains(\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/calder/Documents/kaggle-competition/main.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     j \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/calder/Documents/kaggle-competition/main.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(is_alnum\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.12/site-packages/pandas/core/series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1037\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m   1039\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1040\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m   1042\u001b[0m \u001b[39m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[39m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m \u001b[39mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.12/site-packages/pandas/core/series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1155\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1156\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1158\u001b[0m \u001b[39mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1159\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.12/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text_change'"
     ]
    }
   ],
   "source": [
    "iw_iki(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 32 (4021508445.py, line 34)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[124], line 34\u001b[0;36m\u001b[0m\n\u001b[0;31m    is_iw_iki = is_alnum & is_alnum.shift() #intra-word IKI\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 32\n"
     ]
    }
   ],
   "source": [
    "def calculate_features(df):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Create a DataFrame to store the features with a single column of IDs\n",
    "    features = pd.DataFrame({'id': df['id'].unique()})\n",
    "\n",
    "    \n",
    "    # Long pause calculations\n",
    "    iki = df.groupby('id')['down_time'].diff().fillna(0) #interkeystroke interval\n",
    "    mean_iki = iki.groupby(df['id']).mean().reset_index(name='mean_iki') #mean of IKI\n",
    "    median_iki = iki.groupby(df['id']).median().reset_index(name='median_iki') #median of IKI\n",
    "    std_iki = iki.groupby(df['id']).std().reset_index(name='std_iki') #standard deviation of IKI\n",
    "    max_iki = iki.groupby(df['id']).max().reset_index(name='max_iki') #maximum of IKI\n",
    "\n",
    "    features = features.merge(std_iki, on='id', how='left')\n",
    "\n",
    "    df['word_count'] = word_grouping(df)\n",
    "\n",
    "    # Calculate the difference in down_time within groups defined by both 'id' and 'word_count'\n",
    "    df['down_time_diff'] = df.groupby(['id', 'word_count'])['down_time'].diff()\n",
    "    # Filter out the rows where activity is 'Backspace' or any other non-letter activity\n",
    "    df_filtered = df[df['activity'] == 'Input']\n",
    "    # Calculate the mean difference in down_time within each word for each id\n",
    "    mean_intra_word_iki = df_filtered.groupby(['id', 'word_count'])['down_time_diff'].mean().reset_index()\n",
    "    # Aggregate this feature at the 'id' level to match the granularity of your features DataFrame\n",
    "    mean_intra_word_iki = mean_intra_word_iki.groupby('id')['down_time_diff'].mean().reset_index(name='mean_intra_word_iki')\n",
    "    \n",
    "    # Calculate the standard deviation of down_time_diff within each word for each id\n",
    "    std_intra_word_iki = df_filtered.groupby(['id', 'word_count'])['down_time_diff'].std().reset_index()\n",
    "    # Aggregate this feature at the 'id' level to match the granularity of your features DataFrame\n",
    "    std_intra_word_iki = std_intra_word_iki.groupby('id')['down_time_diff'].std().reset_index(name='std_intra_word_iki')\n",
    "   \n",
    "    # Merge these new features into the features DataFrame\n",
    "    features = features.merge(mean_intra_word_iki, on='id', how='left')\n",
    "    features = features.merge(std_intra_word_iki, on='id', how='left')\n",
    "\n",
    "\n",
    "\n",
    "    #intra_word_iki = df.groupby('id') \n",
    "\n",
    "\n",
    "\n",
    "    #mean_iki_within_word\n",
    "    #std_iki_within_word\n",
    "    \n",
    "    #mean_iki_between_words\n",
    "    #std_iki_between_words\n",
    "\n",
    "    #mean_time_between_words\n",
    "    #std_time_between_words\n",
    "\n",
    "    #mean_time_between_sentences\n",
    "    #std_time_between_sentences\n",
    "    \n",
    "    #n_iki_1\n",
    "    #n_iki_2\n",
    "    #n_iki_3\n",
    "    #n_iki_4\n",
    "    #n_iki_5\n",
    "\n",
    "\n",
    "    # Revision calcuations\n",
    "\n",
    "    # Fluency calculations\n",
    "\n",
    "    # Verbosity calculations\n",
    "\n",
    "    # Non-typing event calculations\n",
    "\n",
    "\n",
    "    return features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_features(df_train)\n",
    "text_change = df_train.groupby('id')['text_change']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.groupby.generic.SeriesGroupBy object at 0x7f615a22fe60>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries to store the features for each ID\n",
    "features = {\n",
    "    'id': [], #user ID \n",
    "    'std_iki': [], #standard deviation of IKI\n",
    "    'pct_pauses': [], #percentage of long pauses between words\n",
    "    'le_revisions': [], #leading-edge revisions\n",
    "    'mean_sb': [], #mean time in single backspacing\n",
    "    'mean_mb': [], #mean time in multiple backspacing\n",
    "    'pct_le_chars': [], #percentage of characters at leading edge\n",
    "    'pct_r_bursts': [], #percentage of R-bursts\n",
    "    'num_prod_cycles': [], #number of production cycles\n",
    "    'ent_per_30': [], #entropy number of keystrokes per 30s\n",
    "    'loc_ext_per_30':[], #local extreme number of keystrokes per 30s\n",
    "    'mean_tcpj': [], #mean time cut/paste/jump events\n",
    "    'SD_tcpj': [], #standard deviation of time cut/paste/jump events\n",
    "    'pct_other':[], #percentage of time spent on other events\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
