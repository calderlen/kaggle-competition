{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Features__\n",
    "- **id**: Users (2471)\n",
    "- **event_id**: Individual event; sequential; starting from 1\n",
    "    - mean: 2070\n",
    "    - SD: 1590\n",
    "    - max: 12900\n",
    "- **down_time**\n",
    "- **up_time**\n",
    "- **action_time**\n",
    "- **activity**\n",
    "    - options\n",
    "        1. Nonproduction\n",
    "        2. Input\n",
    "        3. Remove/Cut\n",
    "        4. Replace\n",
    "        5. Paste\n",
    "        6. Move From [x1, y1] To [x2, y2]\n",
    "- **down_event**\n",
    "- **up_event**\n",
    "    - options\n",
    "        1. q\n",
    "        2. Leftclick\n",
    "        3. .\n",
    "        4. ,\n",
    "        5. Backspace\n",
    "        6. Space\n",
    "        7. \n",
    "- **text_change**\n",
    "    - options\n",
    "        1. NoChange\n",
    "        2. q\n",
    "        3. \n",
    "        4. Replace (ex: qqqqq qqq => qq)\n",
    "        5. \n",
    "- **cursor_position**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### __Derived Keystroke Features__ (From: [Early prediction of writing quality using keystroke logging](https://doi.org/10.1007/s40593-021-00268-w))\n",
    "\n",
    "- Features related to timing of pauses\n",
    "    - **Initial pause time**\n",
    "    - **Total time**\n",
    "    - **IKI**\n",
    "        - *Mean*\n",
    "        - *Median*\n",
    "        - *SD*\n",
    "        - *Max*\n",
    "    - **IKI within word**\n",
    "        - *Mean*\n",
    "        - *SD*\n",
    "    - **IKI between words**\n",
    "        - *Mean*\n",
    "        - *SD*\n",
    "    - **Time between words**\n",
    "        - *Mean*\n",
    "        - *SD*\n",
    "    - **Time between sentences**\n",
    "        - *Mean*\n",
    "        - *SD*\n",
    "    - **Number of IKI of specific length**\n",
    "    - **Percentage long pauses between words**\n",
    "- Features related to revisions\n",
    "    - **Number of revisions**\n",
    "    - **Number of leading-edge revisions**\n",
    "    - **Number of in-text revisions**\n",
    "    - **Number of backspaces**\n",
    "    - **Time in single backspacing**\n",
    "        - *Mean*\n",
    "        - *SD*\n",
    "    - **Percentage of characters in final text**\n",
    "    - **Percentage of characters at leading edge**\n",
    "- Features related to fluency\n",
    "    - **Number of characters per burst**\n",
    "        - *Mean*\n",
    "        - *SD*\n",
    "        - *Max*\n",
    "    - **Number of bursts**\n",
    "    - **Percentage of R-bursts:** number of revision bursts at leading edge ending in a revision\n",
    "    - **Percentage of I-bursts:** number of insertion bursts produced away from the leading edge\n",
    "    - **Percentage of words in P-bursts:** number of words in 'clean' production bursts both initiated and terminated by a long pause (not a revision)\n",
    "    - **Number of production cycles**\n",
    "    - **Percentage of linear transitions between words**\n",
    "    - **Percentage of linear transitions between sentences**\n",
    "- Features related to verbosity\n",
    "    - **Total number of keystrokes**\n",
    "    - **Total number of words**\n",
    "    - **SD number of keystrokes per 30s**\n",
    "    - **Slope of the number of keystrokes per 30s**\n",
    "    - **Entropy of the number of keystrokes per 30s**\n",
    "    - **Uniformity of the number of keystrokes per 30s**\n",
    "    - **Local extreme number of keystrokes per 30s**\n",
    "    - **Distance 30s windows of more than one keystroke**\n",
    "        - *Mean*\n",
    "        - *SD*\n",
    "- Features related to other events\n",
    "    - **Number of focus shifts to translation or task**\n",
    "    - **cut/paste/jump events**\n",
    "        - *Mean*\n",
    "        - *SD*\n",
    "    - **Percentage of time spent on other events**\n",
    "    \n",
    "Note: IKI == Interkeystroke interval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "\n",
    "# absolutely necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# temporarily necessary packages\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "df_train = pd.read_csv('data/train_logs.csv', \n",
    "                 header=0)\n",
    "df_test = pd.read_csv('data/test_logs.csv', \n",
    "                 header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  event_id  down_time  up_time  action_time       activity  \\\n",
      "0  001519c8         1       4526     4557           31  Nonproduction   \n",
      "1  001519c8         2       4558     4962          404  Nonproduction   \n",
      "2  001519c8         3     106571   106571            0  Nonproduction   \n",
      "3  001519c8         4     106686   106777           91          Input   \n",
      "4  001519c8         5     107196   107323          127          Input   \n",
      "\n",
      "  down_event   up_event text_change  cursor_position  word_count  \n",
      "0  Leftclick  Leftclick    NoChange                0           0  \n",
      "1  Leftclick  Leftclick    NoChange                0           0  \n",
      "2      Shift      Shift    NoChange                0           0  \n",
      "3          q          q           q                1           1  \n",
      "4          q          q           q                2           1  \n"
     ]
    }
   ],
   "source": [
    "print(df_train.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2471\n",
      "\n",
      " ['Nonproduction' 'Input' 'Remove/Cut' 'Replace'\n",
      " 'Move From [284, 292] To [282, 290]' 'Move From [287, 289] To [285, 287]'\n",
      " 'Move From [460, 461] To [465, 466]' 'Paste'\n",
      " 'Move From [905, 1314] To [907, 1316]'\n",
      " 'Move From [565, 743] To [669, 847]' 'Move From [669, 847] To [565, 743]'\n",
      " 'Move From [1041, 1121] To [1496, 1576]'\n",
      " 'Move From [1455, 1557] To [1323, 1425]'\n",
      " 'Move From [2268, 2275] To [2247, 2254]'\n",
      " 'Move From [213, 302] To [902, 991]' 'Move From [0, 158] To [234, 392]'\n",
      " 'Move From [460, 465] To [925, 930]' 'Move From [810, 906] To [816, 912]'\n",
      " 'Move From [186, 187] To [184, 185]' 'Move From [140, 272] To [299, 431]'\n",
      " 'Move From [114, 140] To [272, 298]'\n",
      " 'Move From [1386, 1450] To [1445, 1509]'\n",
      " 'Move From [442, 524] To [296, 378]' 'Move From [408, 414] To [390, 396]'\n",
      " 'Move From [1144, 1147] To [1142, 1145]'\n",
      " 'Move From [218, 220] To [206, 208]' 'Move From [164, 165] To [153, 154]'\n",
      " 'Move From [623, 632] To [624, 633]'\n",
      " 'Move From [747, 960] To [1041, 1254]'\n",
      " 'Move From [274, 314] To [299, 339]' 'Move From [624, 625] To [845, 846]'\n",
      " 'Move From [1861, 2063] To [1766, 1968]'\n",
      " 'Move From [1766, 1968] To [1861, 2063]'\n",
      " 'Move From [2091, 2179] To [252, 340]'\n",
      " 'Move From [923, 1077] To [340, 494]' 'Move From [0, 1] To [590, 591]'\n",
      " 'Move From [999, 1000] To [1000, 1001]' 'Move From [13, 65] To [9, 61]'\n",
      " 'Move From [1651, 1769] To [1565, 1683]' 'Move From [61, 136] To [0, 75]'\n",
      " 'Move From [0, 75] To [1, 76]' 'Move From [75, 134] To [304, 363]'\n",
      " 'Move From [289, 355] To [562, 628]'\n",
      " 'Move From [944, 1102] To [1050, 1208]'\n",
      " 'Move From [1306, 1371] To [1061, 1126]'\n",
      " 'Move From [1061, 1126] To [1306, 1371]'\n",
      " 'Move From [1361, 1362] To [1358, 1359]'\n",
      " 'Move From [51, 86] To [109, 144]' 'Move From [134, 169] To [122, 157]'\n",
      " 'Move From [382, 437] To [458, 513]']\n",
      "\n",
      " ['NoChange' 'q' ' ' ... 'qq qqq qqqq qqqqq' 'qq qqqqq qqqq qq qqqqq '\n",
      " '\\n qqqqq qqqqqq qqqqqqqqqq qq q qqqqqqqq qqq qqq qqqq qqqqqq q qqq. \\n\\nqqqq qqq qq qqqqqqq qqq:\\n- \\n- qqq qqqqqqq qqqq q qqqqqq qqqqqqqq qq qqqq qqqqqqqq ']\n",
      "\n",
      " ['Leftclick' 'Shift' 'q' 'Space' 'Backspace' '.' ',' 'Enter' 'ArrowLeft'\n",
      " \"'\" ';' 'ArrowRight' '-' '?' 'Tab' '\"' 'ArrowUp' 'ArrowDown' 'm'\n",
      " 'Rightclick' 'i' 'o' 't' '=' 'a' 'CapsLock' 'Control' 'c' 'v' '/'\n",
      " 'Delete' ':' 'z' '[' '$' '(' ')' '+' 'Home' 'End' '\\\\' 'Meta' '*' '&'\n",
      " 'AudioVolumeMute' 'x' '!' 'Insert' 'MediaPlayPause' 'w' 'NumLock' '%' 'V'\n",
      " 'b' '>' 'Alt' 'AudioVolumeUp' 'ContextMenu' 'AudioVolumeDown' 'n' 'e' '<'\n",
      " 'PageDown' ']' 'Middleclick' '@' 'F12' 'u' 'j' 's' '\\x96' 'Dead' 'y' '{'\n",
      " 'ScrollLock' '¿' 'p' 'Process' '}' 'MediaTrackPrevious' 'MediaTrackNext'\n",
      " 'F3' '^' 'Unidentified' 'Cancel' 'h' '2' 'd' 'r' '`' '\\x9b' 'f' 'g' '#'\n",
      " '~' 'PageUp' 'l' 'T' 'A' 'S' 'ModeChange' '_' 'Escape' 'F11'\n",
      " 'Unknownclick' 'AltGraph' 'F10' 'F15' 'Clear' 'OS' 'C' 'Ä±' 'M' '|'\n",
      " 'â\\x80\\x93' '0' '1' '5' '\\x97' 'Ë\\x86' '¡' '\\x80' 'Â´' 'Å\\x9f' 'F2' 'ä'\n",
      " 'F1' 'k' 'Pause' 'F6']\n"
     ]
    }
   ],
   "source": [
    "print(df_train['id'].nunique())\n",
    "print('\\n',df_train['activity'].unique())\n",
    "print('\\n',df_train['text_change'].unique())\n",
    "print('\\n',df_train['up_event'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     False\n",
      "1     False\n",
      "2     False\n",
      "3      True\n",
      "4      True\n",
      "5      True\n",
      "6      True\n",
      "7      True\n",
      "8      True\n",
      "9     False\n",
      "10     True\n",
      "11     True\n",
      "12     True\n",
      "13    False\n",
      "14     True\n",
      "15     True\n",
      "16     True\n",
      "17     True\n",
      "18     True\n",
      "19     True\n",
      "Name: text_change, dtype: bool\n",
      "(8405898,)\n"
     ]
    }
   ],
   "source": [
    "is_alnum = df_train['text_change'].str.contains('q')\n",
    "print(is_alnum.head(20))\n",
    "print(is_alnum.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_grouping(df):\n",
    "    is_alnum = df['text_change'].str.contains('q')\n",
    "    word_count = [0] * len(is_alnum)  # Initialize with zeros\n",
    "    j = 0\n",
    "\n",
    "    for i in range(len(is_alnum)):\n",
    "        word_count[i] = j\n",
    "        if i < len(is_alnum) - 1:\n",
    "            if not is_alnum.iloc[i] and is_alnum.iloc[i + 1]:\n",
    "                j += 1\n",
    "\n",
    "    word_count[-1] = j  # Last element\n",
    "    \n",
    "    return pd.Series(word_count)  # Return as a Pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(df):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Create a DataFrame to store the features with a single column of IDs\n",
    "    features = pd.DataFrame({'id': df['id'].unique()})\n",
    "\n",
    "    \n",
    "    # ----------- LONG PAUSE CALCULATIONS ------------\n",
    "    iki = df.groupby('id')['down_time'].diff().fillna(0) #interkeystroke interval\n",
    "    mean_iki = iki.groupby(df['id']).mean().reset_index(name='mean_iki') #mean of IKI\n",
    "    median_iki = iki.groupby(df['id']).median().reset_index(name='median_iki') #median of IKI\n",
    "    std_iki = iki.groupby(df['id']).std().reset_index(name='std_iki') #standard deviation of IKI\n",
    "    max_iki = iki.groupby(df['id']).max().reset_index(name='max_iki') #maximum of IKI\n",
    "\n",
    "    features = features.merge(std_iki, on='id', how='left')\n",
    "\n",
    "    df['word_count'] = word_grouping(df)\n",
    "\n",
    "    # Calculate the difference in down_time within groups defined by both 'id' and 'word_count'\n",
    "    df['down_time_diff'] = df.groupby(['id', 'word_count'])['down_time'].diff()\n",
    "    # Filter out the rows where activity is 'Backspace' or any other non-letter activity\n",
    "    df_filtered = df[df['activity'] == 'Input']\n",
    "    # Calculate the mean difference in down_time within each word for each id\n",
    "    mean_intra_word_iki = df_filtered.groupby(['id', 'word_count'])['down_time_diff'].mean().reset_index()\n",
    "    # Aggregate this feature at the 'id' level to match the granularity of your features DataFrame\n",
    "    mean_intra_word_iki = mean_intra_word_iki.groupby('id')['down_time_diff'].mean().reset_index(name='mean_intra_word_iki')\n",
    "    \n",
    "    # Calculate the standard deviation of down_time_diff within each word for each id\n",
    "    std_intra_word_iki = df_filtered.groupby(['id', 'word_count'])['down_time_diff'].std().reset_index()\n",
    "    # Aggregate this feature at the 'id' level to match the granularity of your features DataFrame\n",
    "    std_intra_word_iki = std_intra_word_iki.groupby('id')['down_time_diff'].std().reset_index(name='std_intra_word_iki')\n",
    "    \n",
    "    \n",
    "    \n",
    "    #mean_inter_word_iki\n",
    "    #std_inter_word_iki\n",
    "\n",
    "    #mean_time_between_words\n",
    "    #std_time_between_words\n",
    "\n",
    "    #mean_time_between_sentences\n",
    "    #std_time_between_sentences\n",
    "    \n",
    "    #n_iki_1\n",
    "    #n_iki_2\n",
    "    #n_iki_3\n",
    "    #n_iki_4\n",
    "    #n_iki_5\n",
    "\n",
    "\n",
    "    # Revision calcuations\n",
    "\n",
    "    # Fluency calculations\n",
    "\n",
    "    # Verbosity calculations\n",
    "\n",
    "    # Non-typing event calculations\n",
    "\n",
    "\n",
    "    return features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries to store the features for each ID\n",
    "features = {\n",
    "    'id': [], #user ID \n",
    "    'std_iki': [], #standard deviation of IKI\n",
    "    'pct_pauses': [], #percentage of long pauses between words\n",
    "    'le_revisions': [], #leading-edge revisions\n",
    "    'mean_sb': [], #mean time in single backspacing\n",
    "    'mean_mb': [], #mean time in multiple backspacing\n",
    "    'pct_le_chars': [], #percentage of characters at leading edge\n",
    "    'pct_r_bursts': [], #percentage of R-bursts\n",
    "    'num_prod_cycles': [], #number of production cycles\n",
    "    'ent_per_30': [], #entropy number of keystrokes per 30s\n",
    "    'loc_ext_per_30':[], #local extreme number of keystrokes per 30s\n",
    "    'mean_tcpj': [], #mean time cut/paste/jump events\n",
    "    'SD_tcpj': [], #standard deviation of time cut/paste/jump events\n",
    "    'pct_other':[], #percentage of time spent on other events\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(df):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Create a DataFrame to store the features with a single column of IDs\n",
    "    features = pd.DataFrame({'id': df['id'].unique()})\n",
    "\n",
    "    \n",
    "    # ----------- LONG PAUSE CALCULATIONS ------------\n",
    "    iki = df.groupby('id')['down_time'].diff().fillna(0) #interkeystroke interval\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Compute aggregated statistics\n",
    "    mean_iki = iki.groupby(df['id']).mean().reset_index()\n",
    "    mean_iki.columns = ['id', 'mean_iki']\n",
    "\n",
    "    median_iki = iki.groupby(df['id']).median().reset_index()\n",
    "    median_iki.columns = ['id', 'median_iki']\n",
    "\n",
    "    std_iki = iki.groupby(df['id']).std().reset_index()\n",
    "    std_iki.columns = ['id', 'std_iki']\n",
    "\n",
    "    max_iki = iki.groupby(df['id']).max().reset_index()\n",
    "    max_iki.columns = ['id', 'max_iki']\n",
    "\n",
    "    # Merge with features DataFrame\n",
    "    features = features.merge(mean_iki, on='id', how='left')\n",
    "    features = features.merge(median_iki, on='id', how='left')\n",
    "    features = features.merge(std_iki, on='id', how='left')\n",
    "    features = features.merge(max_iki, on='id', how='left')\n",
    "\n",
    "\n",
    "    df['word_count'] = word_grouping(df)\n",
    "\n",
    "    # Calculate the difference in down_time within groups defined by both 'id' and 'word_count'\n",
    "    df['down_time_diff'] = df.groupby(['id', 'word_count'])['down_time'].diff()\n",
    "    # Filter out the rows where activity is 'Backspace' or any other non-letter activity\n",
    "    df_filtered = df[df['activity'] == 'Input']\n",
    "    # Calculate the mean difference in down_time within each word for each id\n",
    "    mean_intra_word_iki = df_filtered.groupby(['id', 'word_count'])['down_time_diff'].mean().reset_index()\n",
    "    # Aggregate this feature at the 'id' level to match the granularity of your features DataFrame\n",
    "    mean_intra_word_iki = mean_intra_word_iki.groupby('id')['down_time_diff'].mean().reset_index(name='mean_intra_word_iki')\n",
    "    \n",
    "    # Calculate the standard deviation of down_time_diff within each word for each id\n",
    "    std_intra_word_iki = df_filtered.groupby(['id', 'word_count'])['down_time_diff'].std().reset_index()\n",
    "    # Aggregate this feature at the 'id' level to match the granularity of your features DataFrame\n",
    "    std_intra_word_iki = std_intra_word_iki.groupby('id')['down_time_diff'].std().reset_index(name='std_intra_word_iki')\n",
    "    \n",
    "    \n",
    "    \n",
    "    #mean_inter_word_iki\n",
    "    #std_inter_word_iki\n",
    "\n",
    "    #mean_time_between_words\n",
    "    #std_time_between_words\n",
    "\n",
    "    #mean_time_between_sentences\n",
    "    #std_time_between_sentences\n",
    "    \n",
    "    #n_iki_1\n",
    "    #n_iki_2\n",
    "    #n_iki_3\n",
    "    #n_iki_4\n",
    "    #n_iki_5\n",
    "\n",
    "\n",
    "    # Revision calcuations\n",
    "\n",
    "    # Fluency calculations\n",
    "\n",
    "    # Verbosity calculations\n",
    "\n",
    "    # Non-typing event calculations\n",
    "\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = calculate_features(df_train)\n",
    "text_change = df_train.groupby('id')['text_change']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id    mean_iki  median_iki      std_iki   max_iki\n",
      "0     001519c8  702.913962       151.0  4295.447374  154173.0\n",
      "1     0022f953  716.470660       160.0  4894.385161  145968.0\n",
      "2     0042269b  427.170696        94.0  3939.226278  153955.0\n",
      "3     0059420b  875.963368       256.0  4247.568454  101808.0\n",
      "4     0075873a  625.807981       166.0  3896.405072  110824.0\n",
      "...        ...         ...         ...          ...       ...\n",
      "2466  ffb8c745  373.309559       118.0  3457.675123  128628.0\n",
      "2467  ffbef7e5  682.562212       258.0  5632.013483  268008.0\n",
      "2468  ffccd6fd  631.991838       207.0  5399.385611  229911.0\n",
      "2469  ffec5b38  459.114744       168.0  3460.439398  127799.0\n",
      "2470  fff05981  561.021829       169.0  2987.199508  137693.0\n",
      "\n",
      "[2471 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2074089828.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[12], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    features['std_iki'] =\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "features['id'] = df_train['id']\n",
    "features['std_iki'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
